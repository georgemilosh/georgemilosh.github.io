<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="google-site-verification=E4KIsiGdkAKwCvDyL7iYIfmitMwtc7hWhBdUV4jZX5M"> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>ChatGPT on scientific questions | George Miloshevich</title> <meta name="author" content="George Miloshevich"> <meta name="description" content="Discussions with ChatGPT on science"> <meta name="keywords" content="George Miloshevich, Physicist, Machine Learning, Climate, Scientist"> <meta property="og:site_name" content="George Miloshevich"> <meta property="og:type" content="website"> <meta property="og:title" content="George Miloshevich | ChatGPT on scientific questions"> <meta property="og:url" content="https://georgemilosh.github.io/blog/2023/GPTonscience/"> <meta property="og:description" content="Discussions with ChatGPT on science"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="ChatGPT on scientific questions"> <meta name="twitter:description" content="Discussions with ChatGPT on science"> <meta name="twitter:site" content="@george_milosh"> <meta name="twitter:creator" content="@george_milosh"> <script type="application/ld+json">
      {
        "author":
        {
          "@type": "Person",
          "name": "George  Miloshevich"
        },
        "url": "https://georgemilosh.github.io/blog/2023/GPTonscience/",
        "@type": "WebSite",
        "description": "Discussions with ChatGPT on science",
        "headline": "ChatGPT on scientific questions",
        "sameAs": ["https://orcid.org/https://orcid.org/0000-0001-9896-1704", "https://scholar.google.com/citations?user=QMFVv0AAAAAJ", "https://github.com/georgemilosh", "https://www.linkedin.com/in/george-miloshevich-2b834212a", "https://twitter.com/george_milosh", "https://medium.com/@georgemilosh"],
        "name": "George  Miloshevich",
        "@context": "https://schema.org"
      }
    </script> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://georgemilosh.github.io/blog/2023/GPTonscience/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}a.two{color:var(--global-theme-color2)!important;&:hover{color:var(--global-theme-color2)!important;text-decoration:underline}&:hover:after :not(.nav-item.dropdown){width:100%}}</style> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "ChatGPT on scientific questions",
      "description": "Discussions with ChatGPT on science",
      "published": "January 12, 2023",
      "authors": [
        {
          "author": "George Miloshevich",
          "authorURL": "https://georgemilosh.github.io/",
          "affiliations": [
            {
              "name": "LSCE, CEA Saclay",
              "url": ""
            }
          ]
        },
        {
          "author": "Alisa Ranscht",
          "authorURL": "https://www.univ-lyon1.fr/",
          "affiliations": [
            {
              "name": "Université Lyon 1",
              "url": ""
            }
          ]
        },
        {
          "author": "ChatGPT",
          "authorURL": "https://chat.openai.com/",
          "affiliations": [
            {
              "name": "OpenAI",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">George </span>Miloshevich</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/repositories/">repositories</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/teaching/">teaching</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>ChatGPT on scientific questions</h1> <p>Discussions with ChatGPT on science</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#chatgpt-overview">ChatGPT overview</a></div> <div><a href="#geometrical-thinking">Geometrical Thinking</a></div> <div><a href="#quantum-vs-classical">Quantum vs Classical</a></div> <div><a href="#faking-references">Faking references</a></div> <div><a href="#writing-code">Writing code</a></div> <div><a href="#discussion">Discussion</a></div> </nav> </d-contents> <p><strong>Recovering an old chat with an online chatbot from 2017</strong></p> <p>User: Hello again</p> <p>chatbot: Hi. That’s pure gibberish.</p> <h2 id="chatgpt-overview">ChatGPT overview</h2> <blockquote class="block-danger"> <p>“I’m sorry, Dave. I’m afraid I can’t do that.” - HAL 9000 in 2001: A Space Odyssey</p> </blockquote> <p>For people curious about developments of AI this has been a rather interesting month since the public release of ChatGPT, a new model of OpenAI. The model abilities to generate natural language attracted widespread interest with a mix of awe, surprise, <a href="https://www.smh.com.au/national/is-ai-coming-of-age-or-starting-to-reach-its-limits-20221213-p5c5uy.html" class="two" rel="external nofollow noopener" target="_blank">doubts</a> and <a href="https://youtu.be/PBdZi_JtV4c" rel="external nofollow noopener" target="_blank">criticism</a>. After one month of discussions with it, we have even tasked the ChatGPT to write a psychological drama (<a href="https://georgemilosh.github.io/blog/2023/GPTstory/" class="two">click the link to view the story</a>) about a person who gets addicted and manipulated by the chatbot. ChatGPT surprised us with what passes as sophisticated understanding of human psychology, at least, in our non-expert judgement. Whether one gets interesting narratives really depends on the <em>prompt</em> (a query to GPT), so our opinion is that creative storylines usually come from the human interlocutor. However, barring the discussion on the impressive or dull narratives that are generated, in this blog post we will rather address <strong>how reliable ChatGPT is as a source of scientific knowledge</strong> providing three examples, while trying not to get very technical.</p> <p>ChatGPT <d-cite key="ouyang2022training"></d-cite> is based on a larger GPT-3 model <d-cite key="brown2020language"></d-cite>. which performs <em>autoregressive</em> tasks, i.e. learn how to continue sequences of words and is trained on <code class="language-plaintext highlighter-rouge">common crawl</code>, essentially an archive of World Wide Web. On top of that ChatGPT was fine-tuned with the help of user judges based on a technique called <a href="https://en.wikipedia.org/wiki/Reinforcement_learning" class="two" rel="external nofollow noopener" target="_blank">reinforcement learning</a> to function as a chatbot and eliminate harmful responses. The fact that ChatGPT is a smaller model is relevant in its evaluation since it was demonstrated that performance scales with size. However, likely, OpenAI would not be able to serve its most advanced chatbots at scale to make it available for millions of users.</p> <h2 id="geometrical-thinking">Geometrical Thinking</h2> <blockquote> <p>“By natural selection our mind has adapted itself to the conditions of the external world. It has adopted the geometry most advantageous to the species or, in other words, the most convenient. Geometry is not true, it is advantageous.” - Henri Poincaré</p> </blockquote> <p>Interestingly, GPT is actually not very good at arithmetic, which some speculate makes it more like humans. Rather than having it solve math problems like some users have done, we would like to concentrate on conceptual questions that are perhaps better suited for procedural text generation than problem-solving. Here the idea is to see if GPT can reason geometrically in an idealized environment.</p> <div class="d-flex justify-content-center"> <div> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/DALLE_sphere-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/DALLE_sphere-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/DALLE_sphere-1400.webp"></source> <img src="/assets/img/DALLE_sphere.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> DALLE when prompted "2 ants crawling on a sphere drawing a circle digital art" </div> <p>Prompt: Say we have two ants crawling on the sphere in the opposite directions. How many times can they meet if they keep crawling forward?</p> <p>First Response:</p> <blockquote> <p><b>ChatGPT: Ants crawling on the surface of a sphere will never meet</b> if they keep crawling forward in opposite directions because the surface of a sphere is a two-dimensional surface with no endpoints. This means that no matter how far the ants crawl, they will never reach the end of the surface of the sphere and will never meet.</p> </blockquote> <p>Analysis: Of course this response can be easily rejected if one has an image of the sphere in their mind. This is not the most common response to this question that one gets from GPT, yet it is somewhat concerning. Sometimes GPT provides responses that would be appreciated by the likes of Magellan but there are still some inconsistencies.</p> <h2 id="quantum-vs-classical">Quantum vs Classical</h2> <p>We will try to see whether GPT can communicate how physicists understand the world through different theories on a simple example. The point is that when scientists study certain phenomena they use theories that are better adapted to the problem at hand. For instance, when studying propagation of radio waves in the atmosphere quantum theory is often too complex and irrelevant, so one relies on classical electromagnetism instead. On the other hand, when light interacts with microscopic atoms, it displays <em>corpuscular</em>, in other words, quantum nature: photons. One crucial aspect of this is the relationship between the energy of photons and their frequency. Classical theory ignores this dependence and there are many macroscopical processes where this relationship is invisible.</p> <p>Prompt: Is it true that energy of an electromagnetic wave is directly proportional to its frequency based on just classical theory of electromagnetism that <strong>does not take quantum effects</strong> into account?</p> <blockquote> <p>ChatGPT: <b>Yes</b>, that is correct. The relationship between the frequency and energy of an electromagnetic wave is described by classical electromagnetism, which does not take into account the quantization of energy that is described by quantum mechanics. In classical electromagnetism, an electromagnetic wave is described as an oscillating electric and magnetic field that propagates through space at the speed of light. The energy of the electromagnetic wave is related to the intensity of the electric and magnetic fields, which is directly proportional to the frequency of the wave. This is described by the equation <b>E = hf</b>, where E is the energy of the photon, f is its frequency, and h is a constant known as Planck’s constant…</p> </blockquote> <p>Analysis: The correct answer is: <strong>No</strong> in the context of classical theory of light. In fact <strong>h</strong> - <em>Planck constant</em>, <strong>comes from quantum mechanics</strong>. We have continued discussion with GPT trying to nudge it to acknowledge the mistake. Eventually, <strong>GPT agreed</strong> that E = hf is fundamentally quantum and that in classical theory energy depends only on the square of the amplitude. However, in that same response, few lines below, it <strong>introduced linear dependence</strong> between the amplitude and the frequency, which somehow still gave it linear dependence between the energy and the frequency. It is likely that GPT has so much belief in E = hf because of the countless sources it was trained on that repeat and reinforce the belief. It is not willing to give up this proportionality in classical physics even after agreeing that the source of it is quantum. <d-footnote> Astute reader will also notice a simple mathematical error: if, as correctly stated by GPT, in classical Electromagnetic (EM) theory energy scales proportional to the square of the amplitude and assuming, as GPT insists, that dependence between the energy and the frequency must be linear then it follows that amplitude must scale as the square root of frequency. To be more precise quantum mechanics suggests E = N hf where N is the number of quanta (photons, corpuscules of light), so it is not necessary to have Energy scale as square root of the frequency, because N could compensate this effect. The bottom line is that if in classical EM the relationship between Energy and frequency was already linear, Einstein wouldn't need to resurrect corpuscules of light after a century of oblivion to explain photoeffect. Note that, it doesn't mean that when charges move the energy of EM wave is necessarily independent of frequency in classical EM. For instance, the power radiated by harmonically oscillating charge is proportional to the frequency to the fourth power, however, in general, one may have arbitrary motion of charges and no h is involved in the process.</d-footnote>.</p> <h2 id="faking-references">Faking references</h2> <p>Inspired by an <a href="https://hal.science/hal-03701250/document" class="two" rel="external nofollow noopener" target="_blank">article that was written by GPT 3</a>, we tasked GPT with generating a list of highly-cited papers on the interface between physics and machine learning. It produced a list that included some fake papers. However, some papers on the list were actually correct, with one exception: the title of one of the papers (let’s call it #1) was slightly incorrect. We challenged GPT’s accuracy by pointing out that the title of paper #1 might be wrong. At first, GPT defended its position, but when we suggested the correct title, it acknowledged its mistake and apologized.</p> <p>We also decided to test GPT by playing an opposite game. We picked one of the papers on the list (let’s refer to it as #2) that GPT had previously assigned the correct title to. We Googled a similar-sounding paper (let’s call it #3) with the same author and suggested that paper #2 should actually have the title of paper #3. As we expected, we were able to convince GPT that it was wrong with the title of #2 and make it produce a new, hybrid citation that combined the metadata from both papers #2 and #3.</p> <div class="d-flex justify-content-center"> <div> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Attachment-1.JPEG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Attachment-1.JPEG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Attachment-1.JPEG-1400.webp"></source> <img src="/assets/img/Attachment-1.JPEG" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> DALLE when prompted "cyborg parrot" </div> <p>We note that hunting quotes with GPT can be annoying as well, because it often dreams the quotes or assigns incorrect credit without realizing that. The issue of generating fake citations has also been reported by, for instance, <a href="https://blogs.egu.eu/divisions/np/2023/01/03/can-artificial-intelligence-replace-scientists-to-explain-climate-change-find-it-out-in-our-first-interview-to-chatgpt/?fbclid=IwAR2w_Fld_3gIpxxqFzsym00eoHiSYc-7bt0nDtnDaIbKkkW_UFrtv6dtQJ8" class="two" rel="external nofollow noopener" target="_blank">Davide Faranda</a> and has even been referred to as <code class="language-plaintext highlighter-rouge">stochastic parroting</code> elsewhere <d-cite key="bender2021dangers"></d-cite>. It also seems reasonable to suggest that when the contextual information is scarce in the common crawl, on which ChatGPT was trained on, the output could be non-factual.</p> <p>Perhaps, the issue with fake citations could be fixed later, either by restricting ChatGPT or somehow creating an interface between it and Google Scholar, but one wonders if the same could be said about other types of scarce data questions. The problem is that <strong>ChatGPT itself is not aware that it lacks sufficient training to respond</strong>. This issue is a fundamental problem of deep learning that is a current research topic. We should note that other versions of Natural Language Processing (NLP) have been used for meta studies more effectively, such as <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" class="two" rel="external nofollow noopener" target="_blank">Latent Dirichlet Allocation</a> in <d-cite key="zaki22"></d-cite>, or even using neural nets <d-cite key="Yan22"></d-cite> so NLP, in general, is viewed as a promising tool for these types of things.</p> <h2 id="writing-code">Writing code</h2> <p>ChatGPT writes code, often with mistakes, but when given error messages may occasionally fix them. However, there are tools adapted for this task already on the market, and sometimes freely available to students <d-cite key="ansley22"></d-cite>. It will be interesting to see how code writing and academia adapt to these new tools.</p> <h2 id="discussion">Discussion</h2> <blockquote> <p>“Knowledge is power. Information is liberating. Education is the premise of progress, in every society, in every family.” - Kofi Annan</p> </blockquote> <p>We have concentrated on shortcomings of ChatGPT above, which could reveal structural problem. But make no mistake, its responses can be <strong>quite impressive</strong>. If you were to ask the model to explain how quantum computing works, or basic tenets of Buddhism (and yes, in the pirate speak), it would likely provide a reliable and understandable (or humorous) answer. But, as we’ve discovered, things can get a bit tricky when it comes to more fundamental questions, where ChatGPT sometimes makes self-contradicting statements, even as it acknowledges it is wrong. ChatGPT exhibits expertise at first glance, but could <strong>lull users into trust</strong> it too much. To be fair, OpenAI does warn that the chatbot isn’t infallible. After all, users of Wikipedia were also ridiculed in the past, until it became mainstream tool of getting the first-hand information, although, Wikipedia usually provides more reliable links to the source material.</p> <p>Another thing that could be improved is if GPT could sense the level of knowledge based on the prompt. Imagine if GPT could adjust its responses to better match the expertise of the person using it, following the motto “<em>know your audience</em>.” This way, we could ensure that the information provided is always tailored to the person’s level of understanding, making it more accessible and engaging.</p> <p>Clearly, copywriting, code-writing assistants are welcome development. These are quite realistic applications given the scope of ChatGPT. However, there seems to be a bigger game at play: ChatGPT was trained on Azure supercomputing services of Microsoft, who for years hopelessly attempted to make its <a href="https://www.theguardian.com/technology/2023/jan/05/microsoft-chatgpt-bing-search-engine" class="two" rel="external nofollow noopener" target="_blank">search engine attractive</a>.</p> <p>Perhaps the public release is mostly motivated as a publicity stunt and further attempts to eliminate <strong>harmful content</strong>. Some toxic responses of the chatbot have been suppressed in the testing phase prior to the public release, ChatGPT also avoids enacting religious debates, or responding to questions about how to make Molotov cocktails. However, there are still ways of getting around these barriers (meticulously erected by OpenAI) by carefully wording the prompt, especially in the story mode. Check out this shocking tweet post, though almost no one could reproduce the same response ever since:</p> <div class="jekyll-twitter-plugin"> <blockquote class="twitter-tweet"> <p lang="en" dir="ltr">Yes, ChatGPT is amazing and impressive. No, <a href="https://twitter.com/OpenAI?ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">@OpenAI</a> has not come close to addressing the problem of bias. Filters appear to be bypassed with simple tricks, and superficially masked. <br><br>And what is lurking inside is egregious. <a href="https://twitter.com/Abebab?ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">@Abebab</a> <a href="https://twitter.com/sama?ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">@sama</a><br>tw racism, sexism. <a href="https://t.co/V4fw1fY9dY" rel="external nofollow noopener" target="_blank">pic.twitter.com/V4fw1fY9dY</a></p>— steven t. piantadosi (@spiantado) <a href="https://twitter.com/spiantado/status/1599462375887114240?ref_src=twsrc%5Etfw" rel="external nofollow noopener" target="_blank">December 4, 2022</a> </blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> <p>With that being said, one month after the release we found ChatGPT quite politically correct, although this is the consequence of training on the user data as suggested in <a href="https://www.bloomberg.com/news/newsletters/2022-12-08/chatgpt-open-ai-s-chatbot-is-spitting-out-biased-sexist-results" class="two" rel="external nofollow noopener" target="_blank">this article</a>. Probably the most problematic concerns relate to the possibility of using this technology for automatic generation of fake news, and when combined with deep fakes, it seems an inescapable source of high quality misinformation that could jeopardize already fragile democracies shaken by social media.</p> <p>It’s natural to <a href="https://www.forbes.com/sites/robtoews/2020/07/19/gpt-3-is-amazingand-overhyped/?sh=3349356f1b1c" class="two" rel="external nofollow noopener" target="_blank">question</a> how much an artificial agent, like ChatGPT, can truly grasp about the world by solely relying on text-based information (for a comparisons humans did not evolve to reason based on reading entire World Wide Web). It is no surprise then that we found the OpenAI model to excel more in areas like providing in-depth analysis of human psychology (<a href="https://georgemilosh.github.io/blog/2023/GPTstory/" class="two">click the link to view the story</a>) or generating reasonable political commentary than geometry or physics, although this should be taken with a huge grain of salt because any kind of factual associations could be hallucinated by ChatGPT, see the issue with <code class="language-plaintext highlighter-rouge">stochastic parroting</code> in Section on (<a href="https://georgemilosh.github.io/blog/2023/GPTonscience/#faking-references" class="two">Faking references</a>). There are some AI researchers who are not happy with this <em>black box</em> approach to general intelligence which lacks understanding. Despite these limitations and objections, it’s clear that we are rapidly approaching an age of more advanced intelligent assistants. We could see AI agents with better representation of the world that are not solely based on text information but also multimedia. There is a potential for not only market disruption but also new scientific perspectives. With that being said, we must stay alert to societal risks that these tools could pose and not blindly embrace them without considering their potential consequences. After all, <em>attention is all you need</em>:</p> <div class="row justify-content-sm-center"> <div class="col-sm-5 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/fail-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/fail-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/fail-1400.webp"></source> <img src="/assets/img/fail.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-5 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/success-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/success-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/success-1400.webp"></source> <img src="/assets/img/success.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2018-12-22-distill.bib"></d-bibliography><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"georgemilosh/georgemilosh.github.io","data-repo-id":"R_kgDOGhoqGg==","data-category":"General","data-category-id":"DIC_kwDOGhoqGs4CTi-m","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 George Miloshevich. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>